#!/usr/bin/env python3
"""
ç ”ç©¶è€…å‘ã‘ãƒ‡ãƒ¼ã‚¿åˆ†æã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ„ãƒ¼ãƒ«
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ç›´æ¥ç ”ç©¶ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»åˆ†æ
"""

import sqlite3
import json
import datetime
from collections import Counter, defaultdict
import statistics

class ResearchDataAnalyzer:
    """ç ”ç©¶ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_path='kotoiminiki.db'):
        self.db_path = db_path
    
    def get_basic_stats(self):
        """åŸºæœ¬çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # å…¨ãƒ‡ãƒ¼ã‚¿æ•°
        cursor.execute("SELECT COUNT(*) FROM records")
        total_records = cursor.fetchone()[0]
        
        # åŒæ„ãƒ‡ãƒ¼ã‚¿æ•°
        cursor.execute("SELECT COUNT(*) FROM records WHERE consent = TRUE")
        consented_records = cursor.fetchone()[0]
        
        # ãƒ¢ãƒ¼ãƒ‰åˆ¥é›†è¨ˆ
        cursor.execute("SELECT mode, COUNT(*) FROM records WHERE consent = TRUE GROUP BY mode")
        mode_stats = dict(cursor.fetchall())
        
        # å‡ºæ¥äº‹åˆ¥é›†è¨ˆ
        cursor.execute("SELECT event_tag, COUNT(*) FROM records WHERE consent = TRUE GROUP BY event_tag ORDER BY COUNT(*) DESC")
        event_stats = cursor.fetchall()
        
        # æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿æ•°
        cursor.execute("""
            SELECT DATE(timestamp) as date, COUNT(*) 
            FROM records WHERE consent = TRUE 
            GROUP BY DATE(timestamp) 
            ORDER BY date DESC 
            LIMIT 7
        """)
        daily_stats = cursor.fetchall()
        
        conn.close()
        
        return {
            'total_records': total_records,
            'consented_records': consented_records,
            'consent_rate': consented_records / total_records if total_records > 0 else 0,
            'mode_distribution': mode_stats,
            'event_distribution': event_stats,
            'daily_records': daily_stats
        }
    
    def get_quality_analysis(self):
        """ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # å“è³ªãƒ•ãƒ©ã‚°åˆ†æ
        cursor.execute("SELECT quality_flags FROM records WHERE consent = TRUE")
        quality_data = []
        
        for row in cursor.fetchall():
            flags = json.loads(row[0] or '{}')
            quality_data.append(flags)
        
        # å„å“è³ªå•é¡Œã®é›†è¨ˆ
        quality_issues = {
            'spam': sum(1 for q in quality_data if q.get('spam', False)),
            'duplicate': sum(1 for q in quality_data if q.get('duplicate', False)),
            'too_short': sum(1 for q in quality_data if q.get('too_short', False)),
            'high_quality': sum(1 for q in quality_data if not any(q.values()))
        }
        
        # åå¿œæ™‚é–“åˆ†æ
        cursor.execute("SELECT rt_ms FROM records WHERE consent = TRUE")
        reaction_times = [row[0] for row in cursor.fetchall()]
        
        rt_stats = {}
        if reaction_times:
            rt_stats = {
                'mean': statistics.mean(reaction_times),
                'median': statistics.median(reaction_times),
                'min': min(reaction_times),
                'max': max(reaction_times),
                'std': statistics.stdev(reaction_times) if len(reaction_times) > 1 else 0
            }
        
        conn.close()
        
        return {
            'quality_issues': quality_issues,
            'reaction_time_stats': rt_stats,
            'total_analyzed': len(quality_data)
        }
    
    def get_meaning_diversity_analysis(self):
        """æ„å‘³ã¥ã‘ã®å¤šæ§˜æ€§åˆ†æ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # å‡ºæ¥äº‹ã”ã¨ã®æ„å‘³ã¥ã‘åˆ†æ
        cursor.execute("""
            SELECT event_tag, meaning_text, meaning_tag 
            FROM records 
            WHERE consent = TRUE
        """)
        
        event_meanings = defaultdict(list)
        for event_tag, meaning_text, meaning_tag in cursor.fetchall():
            event_meanings[event_tag].append({
                'text': meaning_text,
                'tags': meaning_tag.split(',') if meaning_tag else []
            })
        
        # å„å‡ºæ¥äº‹ã®å¤šæ§˜æ€§è¨ˆç®—
        diversity_results = {}
        for event_tag, meanings in event_meanings.items():
            if len(meanings) < 2:
                continue
                
            # æ„å‘³ã¥ã‘ãƒ†ã‚­ã‚¹ãƒˆã®å¤šæ§˜æ€§ï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯ç‡ï¼‰
            texts = [m['text'] for m in meanings]
            unique_texts = len(set(texts))
            diversity_rate = unique_texts / len(texts)
            
            # ã‚¿ã‚°ã®å¤šæ§˜æ€§
            all_tags = []
            for m in meanings:
                all_tags.extend([tag.strip() for tag in m['tags'] if tag.strip()])
            
            tag_diversity = len(set(all_tags)) / len(all_tags) if all_tags else 0
            
            diversity_results[event_tag] = {
                'total_meanings': len(meanings),
                'unique_meanings': unique_texts,
                'diversity_rate': diversity_rate,
                'tag_diversity': tag_diversity,
                'sample_meanings': texts[:3]
            }
        
        conn.close()
        
        return diversity_results
    
    def get_social_impact_analysis(self):
        """ç¤¾ä¼šçš„å½±éŸ¿åˆ†æï¼ˆä»–è€…ãƒ‡ãƒ¼ã‚¿é–²è¦§ã®å½±éŸ¿ï¼‰"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Social ãƒ¢ãƒ¼ãƒ‰ã§ä»–è€…ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ãŸäººã®åˆ†æ
        cursor.execute("""
            SELECT saw_alt_meanings, changed_after_view, original_meaning, meaning_text
            FROM records 
            WHERE consent = TRUE AND mode = 'social'
        """)
        
        social_data = cursor.fetchall()
        
        total_social = len(social_data)
        saw_alternatives = sum(1 for row in social_data if row[0])  # saw_alt_meanings
        changed_after = sum(1 for row in social_data if row[1])     # changed_after_view
        
        # å¤‰æ›´ä¾‹
        change_examples = []
        for row in social_data:
            if row[1] and row[2] and row[3]:  # changed_after_view and both texts
                change_examples.append({
                    'original': row[2],
                    'revised': row[3]
                })
        
        conn.close()
        
        return {
            'total_social_users': total_social,
            'saw_alternatives': saw_alternatives,
            'changed_after_viewing': changed_after,
            'change_rate': changed_after / saw_alternatives if saw_alternatives > 0 else 0,
            'influence_rate': saw_alternatives / total_social if total_social > 0 else 0,
            'change_examples': change_examples[:5]  # æœ€åˆã®5ä¾‹
        }
    
    def export_research_data(self, filename=None):
        """ç ”ç©¶ãƒ‡ãƒ¼ã‚¿ã‚’CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if not filename:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"research_data_{timestamp}.csv"
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT 
                id, timestamp, mode, event_tag, event_text,
                meaning_text, meaning_tag, rt_ms,
                saw_alt_meanings, changed_after_view,
                quality_flags, original_meaning, revision_count
            FROM records 
            WHERE consent = TRUE
            ORDER BY timestamp
        """)
        
        import csv
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼
            writer.writerow([
                'record_id', 'timestamp', 'mode', 'event_tag', 'event_text',
                'meaning_text', 'meaning_tag', 'reaction_time_ms',
                'saw_alternatives', 'changed_after_view',
                'quality_flags', 'original_meaning', 'revision_count'
            ])
            
            # ãƒ‡ãƒ¼ã‚¿
            for row in cursor.fetchall():
                writer.writerow(row)
        
        conn.close()
        
        return filename

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 60)
    print("ã“ã¨ã‚¤ãƒŸæ—¥è¨˜ - ç ”ç©¶è€…å‘ã‘ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ„ãƒ¼ãƒ«")
    print("=" * 60)
    
    analyzer = ResearchDataAnalyzer()
    
    try:
        print("\nğŸ“Š åŸºæœ¬çµ±è¨ˆæƒ…å ±")
        print("-" * 40)
        basic_stats = analyzer.get_basic_stats()
        print(f"ç·è¨˜éŒ²æ•°: {basic_stats['total_records']}")
        print(f"ç ”ç©¶åŒæ„ãƒ‡ãƒ¼ã‚¿: {basic_stats['consented_records']}")
        print(f"åŒæ„ç‡: {basic_stats['consent_rate']:.1%}")
        print(f"ãƒ¢ãƒ¼ãƒ‰åˆ†å¸ƒ: {basic_stats['mode_distribution']}")
        
        print("\nğŸ” ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ")
        print("-" * 40)
        quality_stats = analyzer.get_quality_analysis()
        print(f"é«˜å“è³ªãƒ‡ãƒ¼ã‚¿: {quality_stats['quality_issues']['high_quality']}")
        print(f"ã‚¹ãƒ‘ãƒ æ¤œå‡º: {quality_stats['quality_issues']['spam']}")
        print(f"é‡è¤‡æ¤œå‡º: {quality_stats['quality_issues']['duplicate']}")
        print(f"çŸ­æ–‡æ¤œå‡º: {quality_stats['quality_issues']['too_short']}")
        
        if quality_stats['reaction_time_stats']:
            rt = quality_stats['reaction_time_stats']
            print(f"å¹³å‡åå¿œæ™‚é–“: {rt['mean']:.0f}ms")
            print(f"ä¸­å¤®å€¤åå¿œæ™‚é–“: {rt['median']:.0f}ms")
        
        print("\nğŸŒˆ æ„å‘³ã¥ã‘å¤šæ§˜æ€§åˆ†æ")
        print("-" * 40)
        diversity_analysis = analyzer.get_meaning_diversity_analysis()
        for event, stats in list(diversity_analysis.items())[:5]:  # ä¸Šä½5ã¤
            print(f"\n{event}:")
            print(f"  è¨˜éŒ²æ•°: {stats['total_meanings']}")
            print(f"  å¤šæ§˜æ€§ç‡: {stats['diversity_rate']:.1%}")
            print(f"  ä¾‹: {stats['sample_meanings'][0][:30]}..." if stats['sample_meanings'] else "  ä¾‹: ãªã—")
        
        print("\nğŸ‘¥ ç¤¾ä¼šçš„å½±éŸ¿åˆ†æ")
        print("-" * 40)
        social_impact = analyzer.get_social_impact_analysis()
        print(f"Socialãƒ¢ãƒ¼ãƒ‰åˆ©ç”¨è€…: {social_impact['total_social_users']}")
        print(f"ä»–è€…ãƒ‡ãƒ¼ã‚¿é–²è¦§è€…: {social_impact['saw_alternatives']}")
        print(f"é–²è¦§å¾Œå¤‰æ›´è€…: {social_impact['changed_after_viewing']}")
        print(f"å¤‰æ›´ç‡: {social_impact['change_rate']:.1%}")
        print(f"å½±éŸ¿ç‡: {social_impact['influence_rate']:.1%}")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        print("\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        print("-" * 40)
        export_choice = input("ç ”ç©¶ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã™ã‹ï¼Ÿ (y/n): ").lower().strip()
        
        if export_choice == 'y':
            filename = analyzer.export_research_data()
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ {filename} ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ")
        
        print("\n" + "=" * 60)
        print("ğŸ¯ ç ”ç©¶åˆ†æå®Œäº†")
        print("\nğŸ“‹ æ¨å¥¨äº‹é …:")
        print("â€¢ Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: http://localhost:8000/research_dashboard")
        print("â€¢ API ã‚¢ã‚¯ã‚»ã‚¹: http://localhost:8000/research?type=comprehensive")
        print("â€¢ è©³ç´°åˆ†æ: è¿½åŠ ã®SQLã‚¯ã‚¨ãƒªã§ã‚«ã‚¹ã‚¿ãƒ åˆ†æå¯èƒ½")
        
    except Exception as e:
        print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        print("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã€ã‚µãƒ¼ãƒãƒ¼ãŒåœæ­¢ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")

if __name__ == '__main__':
    main()